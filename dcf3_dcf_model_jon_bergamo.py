# -*- coding: utf-8 -*-
"""DCF3 DCF Model - Jon Bergamo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l2Pt-bzoF-EyEq_AhJT7M5mirZvRDMRq

# DCF Part 3: Final Model

Here we bring it all together. The end goal here is to get a DCF model-implied share price.

Plan:

1. Start with LTM data to get the most recent starting point
2. Use assumptions about projections. These will be hardcoded up front, including projected revenue growth, margins, and reinvestment rate. All must be for the same number of years in the future.
3. Create projections dataframe such that Year 1 is 12 months from the LTM data we just retrieved.
4. Use projected ratios to generate $-value projections from Revenue to NOPAT to FCF.
5. Discount FCF to the present
6. Compute Terminal Value using Gordon Growth Model, Discount to PV
7. Compute model-implied firm value and compute share price

This is our in-class project that we will work on progressively through the mod.

Expectations:
1. Notebook is clean and neat, with no repeated code. It has clearly labeled sections for inputs/imports at the beginning. Code is sufficiently commented to demonstrate your understanding of the code and help you or anyone else who may use this code later. All numbers should be formatted so they are readable (so, use commas with large numbers, only a few decimal points).
2. All calculations are correct and all discussion questions are answered completely but concisely, demonstrating a depth of understanding.

Workflow:
1. Notebooks are inherently experimental and allow you to try things, however that requires some good habits
2. Once you are "done" in any sense, you always need to "clean up" your notebook to make it presentable. You'd do the same in Excel - you've tried lots of things, etc. but before you present it, you clean it up.
3. Finally, restart the Runtime/Kernel and run it cleanly all the way top to bottom one time.

Then, its ready to go.

# Always put Imports and Installs at the beginning

And only put them in once.

Set display options here if you are using them.

Set API Keys here if you need them.
"""

# necessary imports
import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Set Ticker we are modeling
ticker_symbol = 'MSFT'
company_name = "Microsoft"

#Need to set Effective Tax Rate, validate
eff_tax_rate = 0.19
marg_tax_rate = 0.25

# Set scale Factor
scale_factor = 1000000
scale_name = 'M'

# Format setting for the model - tame the decimals!
pd.reset_option('display.float_format')
pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))

"""## 1 Assumptions about Projection Patterns

This is a "minmimalist" model which means we only need the following:
1. Revenue Growth: To project Revenue
2. EBIT Margin: Go from Revenue to EBIT
3. Effective Tax Rate: Go from EBIT to NOPAT
4. Reinvestment Rate: Go from NOPAT to FCF


"""

ss_growth = 0.03
growth_pattern = [.20, .15, .15, .15, .10, 0.10, 0.10, 0.08, 0.08, 0.06] #must be list the same length as time_horizon

reinv_rate_pattern = [0.4, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]
assert len(growth_pattern) == len(reinv_rate_pattern), "Time patterns do not match - Reinv Rate."

ebit_margin = [0.46, 0.46, 0.46, 0.46, 0.46, 0.46, 0.46, 0.46, 0.46, 0.46]
assert len(growth_pattern) == len(ebit_margin), "Time patterns do not match - EBIT."

time_horizon = len(growth_pattern)
print(f"Length of projection period: {len(growth_pattern)} years")

# Create a Ticker object
ticker = yf.Ticker(ticker_symbol)

# Get shares outstanding data
shares_outstanding = ticker.info['sharesOutstanding']

print(f"Shares Outstanding for {ticker_symbol}: {shares_outstanding/scale_factor:,.2f} {scale_name}")

"""## 2 Need LTM Data for starting point

Yahoo! Finance does not have LTM data - you need to create it yourself. Really all we need is LTM Revenue.
"""

# get LTM data from yfinance
ltm_data = ticker.quarterly_income_stmt.T.sort_index()

# Lets keep just the last four quarters of data using the iloc() method
ltm_data = ltm_data.iloc[-4:]

# print it out
ltm_data

# If you don't have it already, create this variable `ltm_revenue` that is a float (not dataframe), with only revenue, scaled.
ltm_revenue = ltm_data['Total Revenue'].sum()

print(f"Most Recent LTM Revenue for {ticker_symbol} is: (${scale_name}) {ltm_revenue/scale_factor:,.2f}")

# here is the most recent date from which we begin our projections - this should be a datetime data type (not a string or float or int, etc.)
most_recent_date = ltm_data.index[-1]

print(f"Most Recent Date for {ticker_symbol}'s Quarterly Data: {most_recent_date}")

"""## 3 Create dataframe for projections

This is just gathering our assumptions and using the right dates for them
"""

# GIVEN: Just run this code. This is a bit more advanced than I expect most of you can do
#        Feel free to paste it into ChatGPT for a more in-depth explanation.
# this cell gets the dates for our projections going forward

# first, a lookup dictionary that allows us to convert a numeric month to a specific code for datetime objects
# the "A" stands for annual, so these codes will generate Annual intervals starting in that month, which is our goal.
freq_dict = {1:'YE-JAN',2:'YE-FEB',3:'YE-MAR',4:'YE-APR', 5:'YE-MAY',6:'YE-JUN',
             7:'YE-JUL',8:'YE-AUG', 9:'YE-SEP',10:'YE-OCT',11:'YE-NOV',12:'YE-DEC'}

# most_recent_date.month is an integer 1-12 representing the month part of the date.
# So, can you tell what this does?
f = freq_dict[most_recent_date.month]
#print result
print(f"This should match month above for most recent month in the above code cell: {f}\n")

# Generate the new dates for the DataFrame, matching the "growth_pattern" list above
new_dates = pd.date_range(start=most_recent_date, periods=len(growth_pattern)+1, freq=f)

print(f"Dates going forward, starting with time 0:")
print(new_dates)
print("\n")

# Create the projections DataFrame using the new_dates as index
# and the provided lists of projections given above as columns
# BE CAREFUL of dates. The above cell generates a sequence of dates starting today (T=0)
#                      The list objects with projections by definition start at T=1.

# Slice dates to exclude the first (T=0), since projections start at T=1
projections = pd.DataFrame(index=new_dates[1:])

# Build the DataFrame with assumptions
projections['Revenue Growth'] = growth_pattern
projections['EBIT Margin'] = ebit_margin
projections['Reinvestment Rate'] = reinv_rate_pattern

# Display
projections

"""## 4 Now create projections in $"""

# Given LTM revenue and the revenue growth pattern (the python list above)
# generate the $M projections for revenue
# (this may take a few lines of code, not just one or two)

projections['Revenue'] = (ltm_revenue * (1 + projections['Revenue Growth']).cumprod())

# Now compute projected EBIT
# Compute EBIT using Revenue and EBIT Margin
projections['EBIT'] = projections['Revenue'] * projections['EBIT Margin']

# Calculate projected NOPAT (Net Operating Profit After Tax)
projections['NOPAT'] = projections['EBIT'] * (1 - eff_tax_rate)

# Calculate the projected FCF

projections['FCF'] = projections['NOPAT'] * (1 - projections['Reinvestment Rate'])

# Create a list of column names for only the ratios in the projections dataframe
ratios = ['Revenue Growth', 'EBIT Margin', 'Reinvestment Rate']

# Not for the values
values = ['Revenue', 'EBIT', 'NOPAT', 'FCF']

# Now run the scale factor on each of the projected values across revenue, EBIT, NOPAT, and FCF
#projections = projections.apply(lambda x: x * scale_factor)

# print them out
display(projections[ratios])
display(projections[values]/scale_factor)

"""## 5 Get WACC from our WACC notebook

We did this already, so just need to import it.

I put the following prompt in ChatGPT:
```
take this data:

	WACC
0	7.67
1	8.72
2	9.77

and make it so I can turn it into a pandas dataframe if I paste the code
```
"""

# using our WACC notebook and some AI help, create a data frame for WACC.
# It should look like the dataframe shown above in the text block.
# It may take several lines of code.

# Create the WACC data
wacc_data = {
    'WACC': [7.96, 9.25, 10.54]
}

# Convert to DataFrame
wacc_df = pd.DataFrame(wacc_data)

# Display the DataFrame
wacc_df


# Also, for a first pass, we need a single wacc, so set this float value:
wacc = wacc_df.loc[1, 'WACC']/100

print(f"WACC: {wacc:,.4f}")

"""## 6 Discount FCF to Present"""

# Calculate the present value of future cash flows

# Create a time index starting at 1 (T=1 to T=N)
time_periods = np.arange(1, len(projections) + 1)

# Discount each FCF to present value
projections['PV of FCF'] = projections['FCF'] / ((1 + wacc) ** time_periods)

# print
projections[['FCF', 'PV of FCF']]/scale_factor

"""## 7 PV of Terminal Value"""

# Calculate the terminal value using the Gordon Growth Model (also known as the Perpetuity Growth Model)
terminal_value = projections['FCF'].iloc[-1] * ((1 + ss_growth) / (wacc - ss_growth))

print(f"TV for {ticker_symbol}: {terminal_value:,.2f}")

# discount it to the present
present_value_of_terminal = terminal_value / ((1 + wacc) ** time_horizon)

print(f"PV of TV for {ticker_symbol}: {present_value_of_terminal:,.2f}")

"""## 8 Firm Value and Share Price"""

# compute PV of firm value
firm_value = projections['PV of FCF'].sum() + present_value_of_terminal

print(f"Firm Value for {ticker_symbol}: {firm_value:,.2f}")

# compute share price

# Get total debt from the ticker object
total_debt = ticker.info['totalDebt']

# Get total cash from the ticker object
total_cash = ticker.info['totalCash']

share_price = (firm_value - total_debt + total_cash) / shares_outstanding

print(f"Share Price for {ticker_symbol}: ${share_price:,.2f}")

"""## 9 Visualizing Uncertainty

Let's take our upper and lower WACC to quantify the uncertainty in our share price estimate.

What you are doing here is creating a loop from what we just did:
1. Create a for loop that iterates through the three estimates of WACC
2. For each wacc, compute the PV of intermediate CFC, TV, PV of TV and share price
3. The output should be a list of share prices, upper, middle (what we just computed) and lower.

Its good to repeate the middle wacc calculation to validate it is the same as above.
"""

# write code here. This is likely a large block of code, maybe 20 lines or more

# Prepare list for storing results
share_price_estimates = []

# Extract constants
shares_scaled = shares_outstanding / scale_factor
total_debt = ticker.info['totalDebt']
total_cash = ticker.info['totalCash']

# Loop through each WACC value
for wacc_value in wacc_df['WACC']:

    # Convert WACC to decimal if needed
    wacc = wacc_value / 100 if wacc_value > 1 else wacc_value

    # Step 1: Discount FCF to Present
    time_periods = np.arange(1, len(projections) + 1)
    pv_fcfs = projections['FCF'] / ((1 + wacc) ** time_periods)

    # Step 2: Terminal Value and its PV
    terminal_value = projections['FCF'].iloc[-1] * ((1 + ss_growth) / (wacc - ss_growth))
    present_value_of_terminal = terminal_value / ((1 + wacc) ** time_horizon)

    # Step 3: Firm Value
    firm_value = pv_fcfs.sum() + present_value_of_terminal

    # Step 4: Equity Value and Share Price
    equity_value = firm_value - total_debt + total_cash
    share_price = equity_value / shares_outstanding

    # Step 5: Store result
    share_price_estimates.append(share_price)


# output is three stock prices: upper, middle and lower
# print

labels = ['Bear (High WACC)', 'Base (Mid WACC)', 'Bull (Low WACC)']
sorted_results = sorted(zip(share_price_estimates, labels), reverse=True)

print("\n--- Share Price Estimates by WACC Scenario ---")
for price, label in sorted_results:
    print(f"{label}: ${price:,.2f}")

"""Now create a plot!

1. Get 1 year historical stock prices data for the `ticker`
2. Plot it
3. Also plot, as horizontal lines, the upper, middle, and lower stock price estimates
4. Shade the area between the upper and lower stock price

Be sure to use accurate and informative axis labels, plot titles, etc. with correct units.

"""

# Download daily stock prices for the last year
stock_prices = ticker.history(period="1y")['Close']

# Plot the daily stock prices using Seaborn
plt.figure(figsize=(12, 6))
sns.lineplot(data=stock_prices, label='Daily Prices')

# Plot the horizontal lines for the main estimate and the confidence intervals
plt.axhline(y=share_price_estimates[1], color='r', linestyle='--', label='Middle Estimate')
plt.axhline(y=share_price_estimates[0], color='g', linestyle='--', label='Lower Estimate')
plt.axhline(y=share_price_estimates[2], color='b', linestyle='--', label='Upper Estimate')

# Fill between the Upper CI and Lower CI for transparency
plt.fill_between(stock_prices.index, share_price_estimates[0], share_price_estimates[2], color='gray', alpha=0.3, label='Confidence Interval')

# Add title and labels
plt.title(f'{ticker_symbol} Stock Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price ($)')
plt.legend()

# Show the plot
plt.show()